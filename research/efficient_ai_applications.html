<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Efficient AI applications | VSDL</title>

<link rel="icon" href="/vsdl_dpc.github.io/images/icon.jpg">

<meta name="title" content="Efficient AI applications">
<meta name="description" content="by the Greene Lab. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">

<meta property="og:title" content="Efficient AI applications">
<meta property="og:site_title" content="Lab Website Template">
<meta property="og:description" content="by the Greene Lab. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">
<meta property="og:url" content="https://pingchengdong.github.io/vsdl_dpc.github.io">
<meta property="og:image" content="/vsdl_dpc.github.io/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Efficient AI applications">
<meta property="twitter:description" content="by the Greene Lab. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">
<meta property="twitter:url" content="https://pingchengdong.github.io/vsdl_dpc.github.io">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/vsdl_dpc.github.io/images/share.jpg">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "BlogPosting",
      "author": { "@type": "Person", "name": "Example post 3" },
      "datePublished": "2023-02-23T00:00:00+00:00",
      "dateModified": "2024-04-01T19:57:53+00:00",
    
    "name": "Example post 3",
    "description": "by the Greene Lab. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.",
    "headline": "Example post 3",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/lab-website-template/images/icon.png" }
    },
    "url": "https://greenelab.github.io/lab-website-template"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="https://pingchengdong.github.io/vsdl_dpc.github.io/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet">
</noscript>
  
  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/vsdl_dpc.github.io/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/all.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/background.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/body.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/button.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/card.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/code.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/float.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/font.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/form.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/header.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/image.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/link.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/list.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/main.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/section.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/table.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/vsdl_dpc.github.io/_styles/util.css" rel="stylesheet">
  
<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


<script src="/vsdl_dpc.github.io/_scripts/anchors.js"></script>

<script src="/vsdl_dpc.github.io/_scripts/dark-mode.js"></script>

<script src="/vsdl_dpc.github.io/_scripts/fetch-tags.js"></script>

<script src="/vsdl_dpc.github.io/_scripts/search.js"></script>

<script src="/vsdl_dpc.github.io/_scripts/site-search.js"></script>

<script src="/vsdl_dpc.github.io/_scripts/table-wrap.js"></script>

<script src="/vsdl_dpc.github.io/_scripts/tooltip.js"></script>


</head>

  <body>
    







    <header class="background" style="--image: url('/vsdl_dpc.github.io/images/background.jpg')" data-dark="true">
        <a href="/vsdl_dpc.github.io/" class="home">
          
            <img src="/vsdl_dpc.github.io/images/logo3.svg" height="40">
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">Vision and System Design Lab</span>
            
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    <a href="/vsdl_dpc.github.io/" data-tooltip="Home">
        Home
      </a>
      <a href="/vsdl_dpc.github.io/publications/" data-tooltip="Published works">
        Publications
      </a>
      <a href="/vsdl_dpc.github.io/research/" data-tooltip="Research of our group">
        Research
      </a>
      <a href="/vsdl_dpc.github.io/demos/" data-tooltip="Demos, datasets, and more">
        Demos
      </a>
      <a href="/vsdl_dpc.github.io/team/" data-tooltip="About our team">
        Team
      </a>
      <a href="/vsdl_dpc.github.io/blog/" data-tooltip="Musings and miscellany">
        Blog
      </a>
      <a href="/vsdl_dpc.github.io/contact/" data-tooltip="Email, address, and opening">
        Contact
      </a>
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="1" style="--image: url('/lab-website-template/images/photo.jpg')">
    <!--
  background: images/photo.jpg;
  dark: ;
  size: 1;
-->


<h1 class="center">Efficient AI applications</h1>

<div class="post-info">

  
</section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<h3 class="section-title">CAE-GReaT</h3>
<img src="/vsdl_dpc.github.io/images/blog/caegreat2.jpg" alt="caegreat2" width="800"></a>
<p style="text-align: justify;">
  Convolutional Neural Networks (CNNs) and Vision Transformer (ViT) are two primary frameworks for current semantic image recognition tasks in the community of computer vision. The general consensus is that both CNNs and ViT have their latent strengths and weaknesses, e.g., CNNs are good at extracting local features but difficult to aggregate long-range feature dependencies, while ViT is good at aggregating long-range feature dependencies but poorly represents in local features. In this paper, we propose an auxiliary and integrated network architecture, named Convolutional-Auxiliary Efficient Graph Reasoning Transformer (CAE-GReaT), which joints strengths of both CNNs and ViT into a uniform framework. CAE-GReaT stands on the shoulders of the advanced graph reasoning transformer and employs an internal auxiliary convolutional branch to enrich the local feature representations. Besides, to reduce the computational costs in graph reasoning, we also propose an efficient information diffusion strategy. Compared to the existing ViT models, CAE-GReaT not only has the advantage of a purposeful interaction pattern (via the graph reasoning branch), but also can capture fine-grained heterogeneous feature representations (via the auxiliary convolutional branch).<br><br>
</p>

<h3 class="section-title">CTO</h3>
<img src="/vsdl_dpc.github.io/images/papers/2023/2023_CTO.png" alt="caegreat2" width="800"></a>
<p style="text-align: justify;">
  Medical image segmentation is a fundamental task in the community of medical image analysis. In this paper, a novel network architecture, referred to as Convolution, Transformer, and Operator (CTO), is proposed. CTO employs a combination of Convolutional Neural Networks (CNNs), Vision Transformer (ViT), and an explicit boundary detection operator to achieve high recognition accuracy while maintaining an optimal balance between accuracy and efficiency. The proposed CTO follows the standard encoder-decoder segmentation paradigm, where the encoder network incorporates a popular CNN backbone for capturing local semantic information, and a lightweight ViT assistant for integrating long-range dependencies. To enhance the learning capacity on boundary, a boundary-guided decoder network is proposed that uses a boundary mask obtained from a dedicated boundary detection operator as explicit supervision to guide the decoding learning process.<br><br>
</p>

<h3 class="section-title">AUA</h3>
<img src="/vsdl_dpc.github.io/images/papers/2023/2023_TNNLS_Wu.png" alt="caegreat2" width="800"></a>
<p style="text-align: justify;">
  This paper presents a simple yet effective two-stage framework for semi-supervised medical image segmentation. Unlike prior state-of-the-art semi-supervised segmentation methods that predominantly rely on pseudo supervision directly on predictions, such as consistency regularization and pseudo labeling, our key insight is to explore the feature representation learning with labeled and unlabeled (i.e., pseudo labeled) images to regularize a more compact and better-separated feature space, which paves the way for low-density decision boundary learning and therefore enhances the segmentation performance. A stage-adaptive contrastive learning method is proposed, containing a boundary-aware contrastive loss that takes advantage of the labeled images in the first stage, as well as a prototype-aware contrastive loss to optimize both labeled and pseudo labeled images in the second stage. To obtain more accurate prototype estimation, which plays a critical role in prototype-aware contrastive learning, we present an aleatoric uncertainty-aware method, namely AUA, to generate higher-quality pseudo labels. AUA adaptively regularizes prediction consistency by taking advantage of image ambiguity, which, given its significance, is under-explored by existing works. Our method achieves the best results on three public medical image segmentation benchmarks.<br><br>
</p>

<h3 class="section-title">Automated vision-based wellness analysis for elderly care centers</h3>
<center><img src="./images/applications/wellnessanalysis.png" align="middle" style="width:80%"></center>
<p style="text-align: justify;">
  The growth in the aging population require caregivers to improve both efficiency and quality of healthcare. In this study, we develop an automatic, vision-based system for monitoring and analyzing the physical and mental well-being of senior citizens. Through collaboration with Haven of Hope Christian Service, we collect video recording data in the care center with surveillance camera. We then process and extract personalized facial, activity, and interaction features from the video data using deep neural networks. This integrated health information systems can assist caregivers to gain better insights into the seniors they are taking care of. We report findings of our analysis and evaluate the system quantitatively to demonstrate the effectiveness.<br><br>
</p>

<h5 id="conclusion">Reference</h5>
<ol>
<li>Dong Zhang, Yi Lin, Jinhui Tang, Kwang-Ting Cheng. CAE-GReaT: Convolutional-Auxiliary Efficient Graph Reasoning Transformer for Dense Image Predictions. International Journal of Computer Vision, 2023.</li>
<li>Yi Lin, Dong Zhang, Xiao Fang, Yufan Chen, Kwang-Ting Cheng, Hao Chen. Rethinking Boundary Detection in Deep Learning Models for Medical Image Segmentation. International Conference on Information Processing in Medical Imaging, 2023.</li>
<li>Huimin Wu, Xiaomeng Li, Kwang-Ting Cheng. Exploring feature representation learning for semi-supervised medical image segmentation. IEEE Transactions on Neural Networks and Learning Systems, 2023.</li>
<li>Xijie Huang, Jeffry Wicaksana, Shichao Li, Kwang-Ting Cheng. Automated vision-based wellness analysis for elderly care centers. AAAI Workshop: Health Intelligence, 2022.</li>
</ol>

</section>
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

  </section>


    </main>
    


<footer class="background" style="--image: url('/vsdl_dpc.github.io/images/background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>


  <div>
    © 2024
    Vision and System Design Lab
      |   Built with
    <a href="/vsdl_dpc.github.io/team/">
     Team Members
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>